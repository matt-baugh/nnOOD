import argparse
from pathlib import Path

import torch

from nnood.inference.predict import predict_from_folder
from nnood.paths import default_plans_identifier, results_base


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-i', '--input_folder', help='Must contain all modalities for each patient in the correct'
                                                     ' order (same as training). Files must be named CASENAME_XXXX.ext '
                                                     'where XXXX is the modality and ext is the file extension'
                                                     'identifier (0000, 0001, etc)', required=True)
    parser.add_argument('-o', '--output_folder', help='folder for saving predictions', required=True)
    parser.add_argument('-d', '--dataset', help='Dataset which the model was trained on.', required=True)
    parser.add_argument('-t', '--task_name', help='Self-supervised task which the model was trained on', required=True)
    parser.add_argument('-tr', '--trainer_class_name',
                        help='Name of the nnOODTrainer used for full resolution and low resolution U-Net. If you are '
                             'running inference with the cascade and the folder pointed to by --lowres_maps '
                             'does not contain the anomaly maps generated by the low resolution U-Net then the low '
                             'resolution anomaly maps will be automatically generated. For this case, make sure to set '
                             'the trainer class here that matches your --cascade_trainer_class_name.',
                        required=True)
    parser.add_argument('-ctr', '--cascade_trainer_class_name',
                        help='Trainer class name used for predicting the full resolution U-Net part of the cascade.',
                        default=None, required=False)

    parser.add_argument('-m', '--model', help='lowres, fullres or cascade_fullres. Default: fullres',
                        default='fullres', required=False)

    parser.add_argument('-p', '--plans_identifier', help='do not touch this unless you know what you are doing',
                        default=default_plans_identifier, required=False)

    parser.add_argument('-f', '--folds', nargs='+', default='None',
                        help='folds to use for prediction. Default is None which means that folds will be detected '
                             'automatically in the model output folder')

    parser.add_argument('-z', '--save_npz', required=False, action='store_true',
                        help='use this if you want to ensemble these predictions with those of other models.')

    parser.add_argument('-l', '--lowres_scores', required=False, default='None',
                        help='if model is the highres stage of the cascade then you can use this folder to provide '
                             'predictions from the low resolution U-Net (as numpy files). If this is left at default, '
                             'the predictions will be generated automatically (provided that the low resolution U-Net '
                             'network weights are present')

    parser.add_argument('--part_id', type=int, required=False, default=0,
                        help='Used to parallelize the prediction of the folder over several GPUs. If you want to use n '
                             'GPUs to predict this folder you need to run this command n times with --part_id=0, ... '
                             'n-1 and --num_parts=n (each with a different GPU (for example via '
                             'CUDA_VISIBLE_DEVICES=X)')

    parser.add_argument('--num_parts', type=int, required=False, default=1,
                        help='Used to parallelize the prediction of the folder over several GPUs. If you want to use n '
                             'GPUs to predict this folder you need to run this command n times with --part_id=0, ... '
                             'n-1 and --num_parts=n (each with a different GPU (via CUDA_VISIBLE_DEVICES=X)')

    parser.add_argument('--num_threads_preprocessing', required=False, default=6, type=int,
                        help='Determines many background processes will be used for data preprocessing. Reduce this if '
                             'you run into out of memory (RAM) problems. Default: 6')

    parser.add_argument('--num_threads_save', required=False, default=2, type=int,
                        help='Determines many background processes will be used for exporting. Reduce this if you run '
                             'into out of memory (RAM) problems. Default: 2')

    parser.add_argument('--disable_tta', required=False, default=False, action='store_true',
                        help='set this flag to disable test time data augmentation via mirroring. Speeds up inference '
                             'by roughly factor 4 (2D) or 8 (3D)')

    parser.add_argument('--overwrite_existing', required=False, default=False, action='store_true',
                        help='Set this flag if the target folder contains predictions that you would like to overwrite')

    parser.add_argument('--all_in_gpu', type=str, default='None', required=False, help='can be None, False or True. '
                                                                                       'Do not touch.')
    parser.add_argument('--step_size', type=float, default=0.5, required=False, help='don\'t touch')
    parser.add_argument('-chk',
                        help='checkpoint name, default: model_final_checkpoint',
                        required=False,
                        default='model_final_checkpoint')
    parser.add_argument('--disable_mixed_precision', default=False, action='store_true', required=False,
                        help='Predictions are done with mixed precision by default. This improves speed and reduces '
                             'the required vram. If you want to disable mixed precision you can set this flag. Note '
                             'that this is not recommended (mixed precision is ~2x faster!)')

    args = parser.parse_args()
    input_folder = args.input_folder
    output_folder = args.output_folder
    dataset = args.dataset
    part_id = args.part_id
    num_parts = args.num_parts
    folds = args.folds
    save_npz = args.save_npz
    lowres_scores = args.lowres_scores
    num_threads_preprocessing = args.num_threads_preprocessing
    num_threads_save = args.num_threads_save
    disable_tta = args.disable_tta
    step_size = args.step_size
    overwrite_existing = args.overwrite_existing
    all_in_gpu = args.all_in_gpu
    model = args.model
    trainer_class_name = args.trainer_class_name
    cascade_trainer_class_name = args.cascade_trainer_class_name
    task_name = args.task_name

    assert model in ['lowres', 'fullres', 'cascade_fullres'], '-m must be lowres, fullres or cascade_fullres'

    input_folder = Path(input_folder)
    output_folder = Path(output_folder)

    if lowres_scores == 'None':
        lowres_scores = None
    else:
        lowres_scores = Path(lowres_scores)

    if isinstance(folds, list):
        if folds[0] == 'all' and len(folds) == 1:
            pass
        else:
            folds = [int(i) for i in folds]
    elif folds == 'None':
        folds = None
    else:
        raise ValueError('Unexpected value for argument folds')

    assert all_in_gpu in ['None', 'False', 'True']
    if all_in_gpu == 'None':
        all_in_gpu = None
    elif all_in_gpu == 'True':
        all_in_gpu = True
    elif all_in_gpu == 'False':
        all_in_gpu = False

    # we need to catch the case where model is cascade fullres and the low resolution folder has not been set.
    # In that case we need to try and predict with lowres first
    if model == 'cascade_fullres' and lowres_scores is None:
        print('lowres_scores is None. Attempting to predict lowres first...')
        assert part_id == 0 and num_parts == 1, 'if you don\'t specify a --lowres_scores folder for the ' \
                                                'inference of the cascade, custom values for part_id and num_parts ' \
                                                'are not supported. If you wish to have multiple parts, please ' \
                                                'run the lowres inference first (separately)'
        model_folder = Path(results_base, dataset, task_name, 'lowres', trainer_class_name + '__' +
                            args.plans_identifier)
        assert model_folder.is_dir(), 'model output folder not found. Expected: %s' % model_folder
        lowres_output_folder = output_folder / 'lowres_predictions'
        predict_from_folder(model_folder, input_folder, lowres_output_folder, folds, False, num_threads_preprocessing,
                            num_threads_save, None, part_id, num_parts, not disable_tta,
                            mixed_precision=not args.disable_mixed_precision, overwrite_existing=overwrite_existing,
                            overwrite_all_in_gpu=all_in_gpu, step_size=step_size, checkpoint_name=args.chk)
        lowres_scores = lowres_output_folder
        torch.cuda.empty_cache()
        print('lowres done')

    if model == 'cascade_fullres':
        assert cascade_trainer_class_name is not None, 'Cannot use cascade_fullres model without defining' \
                                                       'cascade_trainer_class_name'
        trainer = cascade_trainer_class_name
    else:
        trainer = trainer_class_name

    model_folder = Path(results_base, dataset, task_name, model, trainer + '__' + args.plans_identifier)
    print('using model stored in ', model_folder)
    assert model_folder.is_dir(), 'model output folder not found. Expected: %s' % model_folder

    predict_from_folder(model_folder, input_folder, output_folder, folds, save_npz, num_threads_preprocessing,
                        num_threads_save, lowres_scores, part_id, num_parts, not disable_tta,
                        mixed_precision=not args.disable_mixed_precision, overwrite_existing=overwrite_existing,
                        overwrite_all_in_gpu=all_in_gpu, step_size=step_size, checkpoint_name=args.chk)


if __name__ == '__main__':
    main()
