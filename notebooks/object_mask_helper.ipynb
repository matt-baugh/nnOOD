{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b59e8-dd87-4550-b7a1-757c09ecc258",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from nnood.preprocessing.normalisation import IMAGENET_STATS\n",
    "from nnood.paths import raw_data_base, preprocessed_data_base\n",
    "\n",
    "def wl_to_lh(window, level):\n",
    "    low = level - window / 2\n",
    "    high = level + window / 2\n",
    "    return low,high\n",
    "\n",
    "def display_image(img, phys_size=None, window=None, level=None, existing_ax=None):\n",
    "\n",
    "    if window is None:\n",
    "        window = np.max(img) - np.min(img)\n",
    "\n",
    "    if level is None:\n",
    "        level = window / 2 + np.min(img)\n",
    "\n",
    "    low,high = wl_to_lh(window,level)\n",
    "\n",
    "    if existing_ax is None:\n",
    "        # Display the orthogonal slices\n",
    "        fig, axes = plt.subplots(figsize=(14, 8))\n",
    "    else:\n",
    "        axes = existing_ax\n",
    "\n",
    "    axes.imshow(img, clim=(low, high), extent= None if phys_size is None else (0, phys_size[0], phys_size[1], 0))\n",
    "\n",
    "    if existing_ax is None:\n",
    "        plt.show()\n",
    "        \n",
    "def print_stats(arr):\n",
    "        print(np.mean(arr),', ',np.std(arr))\n",
    "        print(np.min(arr), '-', np.max(arr))\n",
    "        print(arr.shape)\n",
    "        \n",
    "imagenet_channels_stats = [IMAGENET_STATS[list(IMAGENET_STATS.keys())[i]] for i in range(len(IMAGENET_STATS))]\n",
    "\n",
    "def unnormalise(image):\n",
    "    return np.stack([image[i] * imagenet_channels_stats[i][1] + imagenet_channels_stats[i][0] for i in range(image.shape[0])])\n",
    "\n",
    "def get_fig_ax(ncols, nrows):\n",
    "    return plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 5, nrows*5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fbd91-1acc-49e7-8800-06ed20b79041",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nnood.paths import default_data_identifier, default_plans_identifier\n",
    "from nnood.utils.file_operations import load_pickle\n",
    "from nnood.training.dataloading.dataset_loading import load_dataset_filenames, load_npy_or_npz\n",
    "\n",
    "dataset_name = 'mvtec_ad_bottle'\n",
    "\n",
    "plans_file = Path(preprocessed_data_base, dataset_name, default_plans_identifier)\n",
    "test_image_dir = Path(preprocessed_data_base, dataset_name, default_data_identifier + '_stage0')\n",
    "\n",
    "plans = load_pickle(plans_file)\n",
    "\n",
    "dataset = load_dataset_filenames(test_image_dir, plans['dataset_properties']['sample_identifiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4f037-c3cc-4b92-adae-fd86e32f2bea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_img = load_npy_or_npz(dataset['normal_001']['data_file'], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153b767-68bb-466e-8243-6cefee87006e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "from skimage.segmentation import flood\n",
    "from skimage.morphology import binary_opening\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f0966-0701-4582-96e3-fe7b9da79328",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_hypersphere_mask(radius: int, dims: int):\n",
    "    \n",
    "    L = np.arange(-radius, radius + 1)\n",
    "    mg = np.meshgrid(*([L] * dims))\n",
    "    return np.sum([D ** 2 for D in mg], axis=0) <= radius ** 2\n",
    "\n",
    "make_hypersphere_mask(2, 4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454f27f-0765-490e-9fad-fb84d4b4a6f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def get_object_mask(img):\n",
    "        \n",
    "    # Excluding channels dimension\n",
    "    num_channels = img.shape[0]\n",
    "    image_shape = np.array(img.shape)[1:]\n",
    "    \n",
    "    # 5% of each dimension length\n",
    "    corner_lens = image_shape // 20\n",
    "    \n",
    "    # Used for upper_bounds, so use dim lengths\n",
    "    img_corners = list(itertools.product(*[[0, s] for s in image_shape]))\n",
    "    \n",
    "    num_samples_per_c = np.product(corner_lens) // 2\n",
    "    \n",
    "    all_corner_ranges = [[(0, l) if c == 0 else (c - l, c) for c, l in zip(c_coord, corner_lens)]\n",
    "                         for c_coord in img_corners]\n",
    "    corner_patch_slices = [tuple([slice(lb, ub) for lb, ub in cr]) for cr in all_corner_ranges]\n",
    "    \n",
    "    opening_structure_r = max(np.median(image_shape) // 500, 1)\n",
    "    opening_structure = make_hypersphere_mask(opening_structure_r, len(image_shape))\n",
    "    num_corner_seed_points = 3 ** len(image_shape)\n",
    "\n",
    "    masks = []\n",
    "    \n",
    "    for i in range(num_channels):\n",
    "        \n",
    "        sobel_channel = filters.sobel(img[i])                                                           \n",
    "        \n",
    "        curr_channel_masks = []\n",
    "        \n",
    "        for c_c, c_r, c_s in zip(img_corners, all_corner_ranges, corner_patch_slices):\n",
    "            \n",
    "            patch_tolerance = sobel_channel[c_s].std()\n",
    "            \n",
    "            for _ in range(num_corner_seed_points):\n",
    "                random_c = tuple([np.random.randint(lb, ub) for lb, ub in c_r])\n",
    "            \n",
    "                curr_channel_masks.append(flood(sobel_channel, random_c, tolerance=patch_tolerance))\n",
    "        \n",
    "        masks.append(np.any(np.stack(curr_channel_masks), axis=0))\n",
    "        \n",
    "    bg_mask = np.all(np.stack(masks), axis=0)\n",
    "    fg_mask = np.logical_not(bg_mask)\n",
    "    \n",
    "    #\n",
    "    label_fg_mask = label(fg_mask)\n",
    "    region_sizes = np.bincount(label_fg_mask.flatten())\n",
    "    # Zero size of background, so is ignored when finding biggest region\n",
    "    region_sizes[0] = 0\n",
    "    biggest_region_label = np.argmax(region_sizes)\n",
    "    \n",
    "    # Apply binary opening to mask of largest object, to smooth out edges\n",
    "    return binary_opening(label_fg_mask == biggest_region_label, footprint=opening_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb9c78-a1a5-4b5d-800b-3bcb08242789",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display_image(get_object_mask(test_img).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a44b66-b8a5-4615-834e-2dadfe416162",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nnood.data.dataset_conversion.convert_mvtec import CLASS_NAMES, HAS_UNIFORM_BACKGROUND\n",
    "from time import time\n",
    "\n",
    "from nnood.preprocessing.foreground_mask import get_object_mask\n",
    "\n",
    "test_classes = ['toothbrush'] # HAS_UNIFORM_BACKGROUND\n",
    "\n",
    "num_examples = 40\n",
    "fig, ax = get_fig_ax(2, len(test_classes) * num_examples)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for c_n_i in range(len(test_classes)):\n",
    "    \n",
    "    class_name = test_classes[c_n_i]\n",
    "    \n",
    "    curr_dataset_name = 'mvtec_ad_' + class_name\n",
    "    curr_plans_file = Path(preprocessed_data_base, curr_dataset_name, default_plans_identifier)\n",
    "    curr_image_dir = Path(preprocessed_data_base, curr_dataset_name, default_data_identifier + '_stage0')\n",
    "\n",
    "    curr_plans = load_pickle(curr_plans_file)\n",
    "\n",
    "    curr_dataset = load_dataset_filenames(curr_image_dir, curr_plans['dataset_properties']['sample_identifiers'])\n",
    "    \n",
    "    test_imgs = [load_npy_or_npz(curr_dataset[f'normal_{i:03d}']['data_file'], 'r') for i in range(num_examples)]\n",
    "    \n",
    "    test_imgs_masks = [get_object_mask(i).astype(int) for i in test_imgs]\n",
    "    \n",
    "    for j in range(num_examples):\n",
    "        display_image(np.moveaxis(unnormalise(test_imgs[j]), 0, -1), existing_ax=ax[c_n_i * num_examples + j][0])\n",
    "        display_image(test_imgs_masks[j], existing_ax=ax[c_n_i * num_examples + j][1])\n",
    "\n",
    "print('took ', time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc63fc1-eada-4045-a104-94d924661c9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from scipy.stats import energy_distance\n",
    "\n",
    "test_img = imread(Path(raw_data_base, 'mvtec_ad_grid', 'imagesTr', 'normal_000_0000.png'))\n",
    "test_img2 = imread(Path(raw_data_base, 'mvtec_ad_grid', 'imagesTr', 'normal_001_0000.png'))\n",
    "\n",
    "energy_distance(test_img.flatten(), test_img2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d75bec-a9e2-48d2-828f-fc56933e1144",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "INTENSITY_LOGISTIC_PARAMS = {'bottle':(1/12, 24), 'cable':(1/12, 24), 'capsule':(1/2, 4), 'hazelnut':(1/12, 24), 'metal_nut':(1/3, 7), \n",
    "            'pill':(1/3, 7), 'screw':(1, 3), 'toothbrush':(1/6, 15), 'transistor':(1/6, 15), 'zipper':(1/6, 15),\n",
    "            'carpet':(1/3, 7), 'grid':(1/3, 7), 'leather':(1/3, 7), 'tile':(1/3, 7), 'wood':(1/6, 15)}\n",
    "\n",
    "has_uniform_background = ['bottle', 'capsule', 'hazelnut', 'metal_nut', 'pill', 'screw', 'toothbrush', 'zipper']\n",
    "\n",
    "num_test_samples = 10\n",
    "\n",
    "class_stds = []\n",
    "\n",
    "for c_n_i in range(len(CLASS_NAMES)):\n",
    "    \n",
    "    class_name = CLASS_NAMES[c_n_i]\n",
    "    print('Starting ', class_name)\n",
    "    \n",
    "    curr_dataset_name = 'mvtec_ad_' + class_name\n",
    "    \n",
    "    raw_data_folder = Path(raw_data_base, curr_dataset_name, 'imagesTr')\n",
    "    \n",
    "    init_imgs = [imread(raw_data_folder / f'normal_00{i}_0000.png') for i in range(num_test_samples)]\n",
    "\n",
    "    test_imgs = [img[None] if len(img.shape) == 2 else np.moveaxis(img, -1, 0) for img in init_imgs]\n",
    "    \n",
    "    avg_imgs = [np.mean(img, axis=0) for img in test_imgs]\n",
    "    \n",
    "    if class_name in has_uniform_background:\n",
    "        avg_imgs = [a_i[get_object_mask(i)] for a_i, i in zip(avg_imgs, test_imgs)]\n",
    "        \n",
    "    avg_imgs_flat = [i.flatten() for i in avg_imgs]\n",
    "        \n",
    "    energy_distances = []\n",
    "    \n",
    "    for i in range(len(avg_imgs)):\n",
    "        for j in range(len(avg_imgs)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            \n",
    "            energy_distances.append(energy_distance(avg_imgs_flat[i], avg_imgs_flat[j]))\n",
    "            \n",
    "    class_stds.append(np.mean(energy_distances))\n",
    "    \n",
    "print(class_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bd087-5b78-4e52-a277-1100b4ee84c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(zip(CLASS_NAMES, class_stds, [INTENSITY_LOGISTIC_PARAMS[c_n][1] for c_n in CLASS_NAMES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8893d-8ecc-4377-ab83-54f28becf038",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nnood.data.dataset_conversion.convert_mvtec import OBJECTS, TEXTURES\n",
    "\n",
    "plt.xlabel('Average energy distance between images (filtering foreground if possible)')\n",
    "plt.ylabel('Logistic param 1')\n",
    "\n",
    "std_dict = {}\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    c_n = CLASS_NAMES[i]\n",
    "    \n",
    "    std = class_stds[i]\n",
    "    l_p = INTENSITY_LOGISTIC_PARAMS[c_n][1]\n",
    "    std_dict[c_n] = (std, l_p)\n",
    "\n",
    "# exclude bottle as rotation invariant\n",
    "unaligned_objects = ['hazelnut', 'metal_nut', 'screw']\n",
    "has_foreground = [cn for cn in has_uniform_background if cn not in unaligned_objects]\n",
    "other_objects = [cn for cn in OBJECTS if cn not in unaligned_objects and cn not in has_foreground] \n",
    "\n",
    "for cat, m, l in [(TEXTURES, 'gx', 'Textures'), (unaligned_objects, 'ro', 'Unaligned'),\n",
    "               (has_foreground, 'bo', 'Has foreground'), (other_objects, 'go', 'Other objects')]:\n",
    "    \n",
    "    plt.plot([std_dict[c_n][0] for c_n in cat],\n",
    "             [std_dict[c_n][1] for c_n in cat], m, label=l)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2b056-69f4-4aeb-84e5-7831fc48fcaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}